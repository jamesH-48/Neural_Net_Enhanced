Full Print Out Example:
Activation Function:  sigmoid
After 8000 iterations, the total error is 9.100590968102894
Activation Function:  relu
After 8000 iterations, the total error is 4.263637582173963
Activation Function:  tanh
After 8000 iterations, the total error is 3.0444171066901067
err s:
 [[328.55552622]
 [328.32551288]
 [328.0178716 ]
 ...
 [  9.10310459]
 [  9.10184753]
 [  9.10059097]]
err r:
 [[489.21269057]
 [486.38580133]
 [482.63224627]
 ...
 [  4.26613564]
 [  4.26477815]
 [  4.26363758]]
err t:
 [[382.09043976]
 [380.0198754 ]
 [377.26284018]
 ...
 [  3.04679704]
 [  3.04560701]
 [  3.04441711]]
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      8000|    0.1|   456|547| 766| 46| 2| 4|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  98.78444084278767 %
Mean Squared Error:  9.0993349
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  99.27536231884058 %
Mean Squared Error:  0.85097443 

Train Accuracy Results for  relu  activation function:
Percent Correct:  99.27066450567261 %
Mean Squared Error:  4.26253429
Test Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.07403894 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  99.83792544570503 %
Mean Squared Error:  3.04322732
Test Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.27584008 
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 1000 iterations, the total error is 223.36450155572254
Activation Function:  relu
After 1000 iterations, the total error is 215.1603347640882
Activation Function:  tanh
After 1000 iterations, the total error is 35.22464508559133
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      1000|    0.3|   456|547| 766| 46| 1| 1|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  47.91666666666667 %
Mean Squared Error:  223.33138283
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  46.84466019417476 %
Mean Squared Error:  96.14005851 

Train Accuracy Results for  relu  activation function:
Percent Correct:  17.083333333333332 %
Mean Squared Error:  215.11222962
Test Accuracy Results for  relu  activation function:
Percent Correct:  16.019417475728158 %
Mean Squared Error:  93.18660513 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  94.47916666666667 %
Mean Squared Error:  35.12806307
Test Accuracy Results for  tanh  activation function:
Percent Correct:  95.63106796116504 %
Mean Squared Error:  15.3679801 
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 5000 iterations, the total error is 49.097826496758636
Activation Function:  relu
After 5000 iterations, the total error is 16.815182835165267
Activation Function:  tanh
After 5000 iterations, the total error is 8.17061109869453
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      5000|    0.3|   456|547| 766| 46| 2| 2|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  98.95833333333334 %
Mean Squared Error:  49.08085933
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  99.02912621359224 %
Mean Squared Error:  21.06606292 

Train Accuracy Results for  relu  activation function:
Percent Correct:  96.875 %
Mean Squared Error:  16.8109994
Test Accuracy Results for  relu  activation function:
Percent Correct:  98.05825242718447 %
Mean Squared Error:  6.86508072 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  98.75 %
Mean Squared Error:  8.16998592
Test Accuracy Results for  tanh  activation function:
Percent Correct:  98.54368932038835 %
Mean Squared Error:  3.3625419 
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 8000 iterations, the total error is 19.35383614948153
Activation Function:  relu
After 8000 iterations, the total error is 5.153520454960798
Activation Function:  tanh
After 8000 iterations, the total error is 6.44702354196199
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      8000|    0.3|   456|547| 766| 46| 2| 2|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  99.0625 %
Mean Squared Error:  19.34852717
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  99.02912621359224 %
Mean Squared Error:  8.10293383 

Train Accuracy Results for  relu  activation function:
Percent Correct:  98.85416666666667 %
Mean Squared Error:  5.15282477
Test Accuracy Results for  relu  activation function:
Percent Correct:  98.7864077669903 %
Mean Squared Error:  1.89578172 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  98.75 %
Mean Squared Error:  6.44651594
Test Accuracy Results for  tanh  activation function:
Percent Correct:  98.54368932038835 %
Mean Squared Error:  2.51915591 
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 8000 iterations, the total error is 0.3204876066900101
Activation Function:  relu
After 8000 iterations, the total error is 3.6677878291208152
Activation Function:  tanh
After 8000 iterations, the total error is 0.23242613059503286
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      8000|    0.3|   456|547| 766| 46| 8| 8|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.32030174
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.13820324 

Train Accuracy Results for  relu  activation function:
Percent Correct:  99.27083333333333 %
Mean Squared Error:  3.66764946
Test Accuracy Results for  relu  activation function:
Percent Correct:  99.02912621359224 %
Mean Squared Error:  1.74210803 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.23228156
Test Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.10464987
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 1000 iterations, the total error is 194.673519174089
Activation Function:  relu
After 1000 iterations, the total error is 29.494824224507383
Activation Function:  tanh
After 1000 iterations, the total error is 18.214957678114704
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      1000|    0.1|   456|547| 766| 46| 3| 3|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  95.86709886547811 %
Mean Squared Error:  194.54638883
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  96.37681159420289 %
Mean Squared Error:  22.21351869 

Train Accuracy Results for  relu  activation function:
Percent Correct:  96.51539708265803 %
Mean Squared Error:  29.43519143
Test Accuracy Results for  relu  activation function:
Percent Correct:  98.55072463768117 %
Mean Squared Error:  1.98716777 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  98.70340356564019 %
Mean Squared Error:  18.19481412
Test Accuracy Results for  tanh  activation function:
Percent Correct:  99.27536231884058 %
Mean Squared Error:  2.17270341 
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 5000 iterations, the total error is 8.238867728314798
Activation Function:  relu
After 5000 iterations, the total error is 13.967999947218754
Activation Function:  tanh
After 5000 iterations, the total error is 3.057372276295706
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      5000|    0.1|   456|547| 766| 46| 4| 4|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  99.91896272285251 %
Mean Squared Error:  8.23443587
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.87717873 

Train Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  13.96579435
Test Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  1.51521078 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  3.05539084
Test Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.32825135 
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 5000 iterations, the total error is 3.5511230162867755
Activation Function:  relu
After 5000 iterations, the total error is 11.287246414093486
Activation Function:  tanh
After 5000 iterations, the total error is 3.591605833010065
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      5000|    0.1|   456|547| 766| 46| 4| 8|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  3.54916529
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.42907037 

Train Accuracy Results for  relu  activation function:
Percent Correct:  99.10858995137764 %
Mean Squared Error:  11.2756773
Test Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  1.17863906 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  99.75688816855754 %
Mean Squared Error:  3.58998173
Test Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.51798442 
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 8000 iterations, the total error is 0.5229341533031895
Activation Function:  relu
After 8000 iterations, the total error is 0.921329459842297
Activation Function:  tanh
After 8000 iterations, the total error is 1.0197885160162126
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      8000|    0.1|   456|547| 766| 46| 4| 8|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.52259961
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.06204277 

Train Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.92088136
Test Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.12936176 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  99.91896272285251 %
Mean Squared Error:  1.01899795
Test Accuracy Results for  tanh  activation function:
Percent Correct:  99.27536231884058 %
Mean Squared Error:  0.36587834 
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 9000 iterations, the total error is 0.280368709369226
Activation Function:  relu
After 9000 iterations, the total error is 0.5590191906490207
Activation Function:  tanh
After 9000 iterations, the total error is 0.30041261813010667
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      9000|    0.1|   456|547| 766| 46| 4| 8|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.28019728
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.03302038 

Train Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.55876577
Test Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.13917338 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.30011258
Test Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.10860142 
----------------------------------------------------------------------------
Last one repeated with 3 more unique state configurations.
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 9000 iterations, the total error is 0.518985310159155
Activation Function:  relu
After 9000 iterations, the total error is 5.363563508390502
Activation Function:  tanh
After 9000 iterations, the total error is 0.4071543021761362
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      9000|    0.1|   98|76| 364| 379| 4| 8|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.51865016
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.02484892 

Train Accuracy Results for  relu  activation function:
Percent Correct:  99.27066450567261 %
Mean Squared Error:  5.36264946
Test Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.20950384 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.40687699
Test Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.03579482 
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 9000 iterations, the total error is 0.5757735045444476
Activation Function:  relu
After 9000 iterations, the total error is 1.2158780407053085
Activation Function:  tanh
After 9000 iterations, the total error is 0.07770058606769376
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      9000|    0.1|   125|855| 921| 255| 4| 8|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.57538324
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.05959288 

Train Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  1.21542766
Test Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.22236594 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.07766519
Test Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.01129105 
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 9000 iterations, the total error is 0.5776874090490012
Activation Function:  relu
After 9000 iterations, the total error is 0.11993439704258824
Activation Function:  tanh
After 9000 iterations, the total error is 0.1231737518347481
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      9000|    0.1|   777|777| 234| 234| 4| 8|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.577336
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.07459177 

Train Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.11979031
Test Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.00988809 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.1231103
Test Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.01307269 
----------------------------------------------------------------------------
Same configuration as before but with more iterations to test accuracy
----------------------------------------------------------------------------
Activation Function:  sigmoid
After 15000 iterations, the total error is 0.02016930058462095
Activation Function:  relu
After 15000 iterations, the total error is 1.2957434105340702e-06
Activation Function:  tanh
After 15000 iterations, the total error is 0.006789649019993627
Iterations|Test Size|Seed1|Seed2|state|Randseed|h1|h2|
      15000|    0.1|   777|777| 234| 234| 4| 8|

Train Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.02015847
Test Accuracy Results for  sigmoid  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.00255504 

Train Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  1.29e-06
Test Accuracy Results for  relu  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  3e-08 

Train Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.00678666
Test Accuracy Results for  tanh  activation function:
Percent Correct:  100.0 %
Mean Squared Error:  0.00076123 